{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class args(object):\n",
    "    \n",
    "    #### DATA  ####\n",
    "    node_size = 21 # equals to the number of nodes + 1 (zero_padding)\n",
    "    seq_len = 5\n",
    "    \n",
    "    #### Training ####\n",
    "    batch_size = 32\n",
    "    lr = 0.0002\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    LSTM_maxnorm = 0.25\n",
    "    acc_threshold = 0.5\n",
    "    try_valid = 20\n",
    "    running_loss = True\n",
    "    n_epoch = 50\n",
    "    weight_reg = 0\n",
    "    \n",
    "    \n",
    "    #### Model ####\n",
    "    RNN_model = 'gru'\n",
    "    hidden_size = 50\n",
    "    num_layers = 5\n",
    "    embedding_dim = 50\n",
    "    embedding_maxnorm = None\n",
    "    bidirectional = True\n",
    "    model_name = 'Siamese' \n",
    "    model_path ='./'+ model_name +'/Model/'\n",
    "    \n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)\n",
    "\n",
    "'''\n",
    "TODO:\n",
    "\n",
    "1. Add GRU\n",
    "2. Add Algo\n",
    "'''   \n",
    "\n",
    "with open(\"Planar10thData.txt\", \"rb\") as fp:   # Unpickling\n",
    "    df = pickle.load(fp)\n",
    "X = df[['left','right']]     \n",
    "Y = df['target']    \n",
    "del df\n",
    "\n",
    "#Seperate to training, validation, and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 64)\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size= 0.05,random_state= 64)\n",
    "Y_test = Y_test.values\n",
    "Y_train = Y_train.values\n",
    "Y_validation = Y_validation.values\n",
    "\n",
    "#Check shape\n",
    "assert X_train['left'].shape == X_train['right'].shape\n",
    "assert len(X_train['left']) == len(Y_train)\n",
    "\n",
    "def padding(data):\n",
    "    left = [] \n",
    "    for i in range(data.shape[0]):\n",
    "        left.append((data.iloc[i]['left']))\n",
    "    right = [] \n",
    "    for i in range(data.shape[0]):\n",
    "        right.append((data.iloc[i]['right']))\n",
    "    return torch.tensor(np.array([right,left])).transpose(1,0)\n",
    "\n",
    "\n",
    "def plot_train_hist(train_hist, step = None, ):\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    for name in train_hist.keys():\n",
    "        if 'Loss' in name:\n",
    "            plt.subplot(211)\n",
    "            plt.plot(train_hist[name],marker='o',label= name)\n",
    "            plt.ylabel('Loss',fontsize=15)\n",
    "            plt.xlabel('Number of epochs',fontsize=15)\n",
    "            plt.title('Loss',fontsize=20,fontweight =\"bold\")\n",
    "            plt.legend(loc='upper left')\n",
    "        else:\n",
    "            plt.subplot(212)\n",
    "            plt.plot(train_hist[name],marker='o',label= name)\n",
    "            plt.ylabel('Accuracy',fontsize=15)\n",
    "            plt.xlabel('Number of epochs',fontsize=15)\n",
    "            plt.title('Accuracy',fontsize=20,fontweight =\"bold\")\n",
    "            plt.legend(loc='upper left')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if step is not None:\n",
    "        fig.savefig(\"Train_Hist\"+str(step)+\".png\") \n",
    "\n",
    "\n",
    "#Padding and creat the loaders\n",
    "X_train = padding(X_train)\n",
    "Y_train = torch.FloatTensor(np.array(Y_train))\n",
    "train_dataset  = Data.TensorDataset(X_train,Y_train)\n",
    "\n",
    "X_validation = padding(X_validation)\n",
    "Y_validation = torch.FloatTensor(np.array(Y_validation))\n",
    "val_dataset  = Data.TensorDataset(X_validation,Y_validation)\n",
    "\n",
    "X_test = padding(X_test)\n",
    "Y_test = torch.FloatTensor(np.array(Y_test))\n",
    "test_dataset  = Data.TensorDataset(X_test,Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Encoder(nn.Module):\n",
    "    def __init__(self, model = 'lstm'):\n",
    "        super(RNN_Encoder, self).__init__()\n",
    "        \n",
    "        # No need for padding, but if we need the padding, we have to set the idx as 0\n",
    "        # So that's why we need to make the graph start from 0\n",
    "        self.model = model\n",
    "        self.embedding = nn.Embedding(args.node_size, embedding_dim = args.embedding_dim, padding_idx=0,\n",
    "                                      max_norm = args.embedding_maxnorm)\n",
    "        \n",
    "\n",
    "        if args.bidirectional:\n",
    "            num_dir = 2\n",
    "            fc_size1= args.hidden_size*args.seq_len*2\n",
    "            fc_size2= 128\n",
    "        else:\n",
    "            num_dir = 1\n",
    "            fc_size1= args.hidden_size\n",
    "            fc_size2= 16\n",
    "            \n",
    "        self.fc= nn.Sequential(\n",
    "            nn.Linear(fc_size1,fc_size2),\n",
    "            nn.BatchNorm1d(fc_size2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(fc_size2,2),\n",
    "        )\n",
    "        \n",
    "        self.h0 = nn.Parameter(torch.randn(args.num_layers*num_dir, 1, args.hidden_size))\n",
    "        \n",
    "        if self.model == 'lstm':\n",
    "            self.rnn = nn.LSTM(input_size = args.embedding_dim, hidden_size = args.hidden_size,\n",
    "                           num_layers = args.num_layers, bidirectional = args.bidirectional, batch_first = True)\n",
    "            self.c0 = nn.Parameter(torch.ones(args.num_layers*num_dir, 1, args.hidden_size))\n",
    "            print('Using LSTM')\n",
    "        elif self.model == 'gru':\n",
    "            self.rnn = nn.GRU(input_size= args.embedding_dim, hidden_size= args.hidden_size,\n",
    "                              num_layers = args.num_layers, bidirectional = args.bidirectional, batch_first = True)\n",
    "            print('Using GRU')\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        B = x.size(0)\n",
    "        \n",
    "        out = self.embedding(x)\n",
    "        \n",
    "        if self.model == 'lstm':\n",
    "            h_ = (self.h0.repeat(1,B,1), self.c0.repeat(1,B,1))\n",
    "        elif self.model == 'gru':\n",
    "            h_ = self.h0.repeat(1,B,1)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        out, hidden = self.rnn(out, h_)\n",
    "        \n",
    "        if args.bidirectional:\n",
    "            out = self.fc(out.contiguous().view(B,-1))\n",
    "        else:\n",
    "            out = self.fc(out[:,-1,:])\n",
    "        return out\n",
    "    \n",
    "    \n",
    "\n",
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(SiameseNet, self).__init__()\n",
    "        \n",
    "        self.encoder = RNN_Encoder(args.RNN_model)\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.train_hist = defaultdict(list)\n",
    "        self.acc_hist = []\n",
    "        self.apply(self.weight_init)\n",
    "        \n",
    "        self.optim = optim.Adam(self.encoder.parameters(), lr = args.lr, betas= (args.beta1, args.beta2),\n",
    "                                weight_decay = args.weight_reg)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        \n",
    "        self.optim.zero_grad()\n",
    "        left = x[:,0,:]\n",
    "        right = x[:,1,:]\n",
    "        \n",
    "        left_out = self.encoder(left)\n",
    "        right_out = self.encoder(right)\n",
    "        self.prediction = torch.exp(-torch.norm((left_out - right_out),1,-1))\n",
    "        self.loss = self.mse(self.prediction, y)\n",
    "        self.take = left_out - right_out\n",
    "        \n",
    "        if args.LSTM_maxnorm is not None:\n",
    "            nn.utils.clip_grad_norm_(self.encoder.rnn.parameters(), args.LSTM_maxnorm)\n",
    "        self.acc = torch.mean(((self.prediction>args.acc_threshold) == (y.byte())).float())\n",
    "        self.train_hist['Loss'].append(self.loss.item())\n",
    "        self.train_hist['Accuracy'].append(self.acc.item())\n",
    "        self.loss.backward()\n",
    "        self.optim.step()\n",
    "        \n",
    "    def weight_init(self,m):\n",
    "        if type(m) in [nn.Conv2d, nn.ConvTranspose2d, nn.Linear]:\n",
    "            nn.init.kaiming_normal_(m.weight,0.2,nonlinearity='leaky_relu')\n",
    "        elif type(m) in [nn.LSTM]:\n",
    "            for name, value in m.named_parameters():\n",
    "                if 'weight' in name :\n",
    "                    nn.init.xavier_normal_(value.data)\n",
    "                if 'bias'in name:\n",
    "                    value.data.normal_()\n",
    "                    \n",
    "    def model_save(self,step):\n",
    "        \n",
    "        path = args.model_path + args.model_name+'_Step_' + str(step) + '.pth'\n",
    "        torch.save({args.model_name:self.state_dict()}, path)\n",
    "        print('Model Saved')\n",
    "        \n",
    "    def load_step_dict(self, step):\n",
    "        \n",
    "        path = args.model_path + args.model_name +'_Step_' + str(step) + '.pth'\n",
    "        self.load_state_dict(torch.load(path, map_location = lambda storage, loc: storage)[args.model_name])\n",
    "        print('Model Loaded')\n",
    "        \n",
    "           \n",
    "    def plot_all_loss(self, step):\n",
    "        fig = plt.figure(figsize=(20, 10))\n",
    "        num_loss = 2\n",
    "        i = 0\n",
    "        for name in self.train_hist.keys():\n",
    "            if 'V' not in name:\n",
    "                i+= 1\n",
    "                fig.add_subplot(num_loss,1,i)\n",
    "                plt.plot(self.train_hist[name], label = name)\n",
    "                plt.xlabel('Number of Steps',fontsize=15)\n",
    "                plt.ylabel( name, fontsize=15)\n",
    "                plt.title(name, fontsize=30, fontweight =\"bold\")\n",
    "                plt.legend(loc = 'upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        fig.savefig(\"Train_Hist\"+str(step)+\".png\") \n",
    "        \n",
    "    def test_step(self, x, y):\n",
    "        \n",
    "        left = x[:,0,:]\n",
    "        right = x[:,0,:]\n",
    "        \n",
    "        left_out = self.encoder(left)\n",
    "        right_out = self.encoder(right)\n",
    "        \n",
    "        self.v_prediction = torch.exp(-torch.norm((left_out - right_out),1,-1)).detach()\n",
    "        self.v_loss = self.mse(self.v_prediction, y)\n",
    "        self.v_acc = torch.mean(((self.v_prediction>args.acc_threshold) == (y.byte())).float())\n",
    "        self.train_hist['V_Loss'].append(self.v_loss.item())\n",
    "        self.train_hist['V_Accuracy'].append(self.v_acc.item())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = args.batch_size, shuffle=True, drop_last = True)\n",
    "valid_loader = DataLoader(val_dataset, batch_size = args.batch_size, shuffle=True, drop_last= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.weight_reg = 0\n",
    "siamese = SiameseNet().to(device)\n",
    "siamese.train()\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(siamese.optim, milestones=[20,40,60,80], gamma=0.5)\n",
    "siamese.optim.param_groups[0]['lr']= 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = defaultdict(list)\n",
    "args.running_loss = True\n",
    "args.n_epoch = 50\n",
    "all_step = 0\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while epoch < args.n_epoch:\n",
    "    siamese.train()\n",
    "    for i,(data, label) in enumerate(train_loader):\n",
    "\n",
    "        \n",
    "        start_t = time.time()\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        siamese(data, label)\n",
    "        end_t = time.time()\n",
    "        all_step += 1\n",
    "        print('| Epoch [%d] | Step [%d] | lr [%.6f] | Loss: [%.4f] | Acc: [%.4f] | Time: %.1fs' %\\\n",
    "              ( epoch, all_step, siamese.optim.param_groups[0]['lr'], siamese.loss.item() , siamese.acc.item() ,\n",
    "                end_t - start_t))\n",
    "    \n",
    "    if i % 1 == 0:\n",
    "        siamese.eval()\n",
    "        for j, (v_data, v_label) in enumerate(valid_loader):\n",
    "\n",
    "            start_t = time.time()\n",
    "            v_data = v_data.to(device)\n",
    "            v_label = v_label.to(device)\n",
    "            siamese.test_step(v_data, v_label)\n",
    "            end_t = time.time()\n",
    "            print('| Epoch [%d] | Validation | Step [%d] |  Loss: [%.4f] | Acc: [%.4f] | Time: %.1fs' %\\\n",
    "                  ( epoch, j, siamese.v_loss.item() , siamese.v_acc.item() ,end_t - start_t))\n",
    "                \n",
    "    siamese.plot_all_loss('Training_0reg')\n",
    "    \n",
    "    if epoch >= 1:\n",
    "        plot_train_hist(train_hist, 'Epoch_0reg')\n",
    "\n",
    "    for name in siamese.train_hist.keys():\n",
    "        train_hist[name].append(sum(siamese.train_hist[name])/len(siamese.train_hist[name]))\n",
    "\n",
    "    if not args.running_loss:\n",
    "        for name in siamese.train_hist.keys():\n",
    "            siamese.train_hist[name] = []\n",
    "    epoch += 1\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        siamese.model_save(epoch)\n",
    "    \n",
    "    if epoch >= 0:\n",
    "        raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### This Algorithm can solve the problem and make the graph in a batch of training data #####\n",
    "\n",
    "class Graph_Alg(object):\n",
    "    \n",
    "    def __init__(self,):\n",
    "        self.G = nx.Graph()\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        \n",
    "        paired_data = np.array(x[y.byte()])\n",
    "        for i in paired_data:\n",
    "            for j in i:\n",
    "                for k in range(len(j)):\n",
    "                    if not j[k] in self.G.nodes:\n",
    "                        self.G.add_node(j[k])\n",
    "                    if k >= 1:\n",
    "                        if not (j[k],j[k-1]) in self.G.edges:\n",
    "                            self.G.add_edge(j[k],j[k-1])\n",
    "                            \n",
    "    def draw(self,):\n",
    "        \n",
    "        nx.draw(self.G, with_labels=True, font_weight='bold')\n",
    "        plt.show()\n",
    "        \n",
    "    def test(self, x, y):\n",
    "        \n",
    "        out = []\n",
    "        paired_data = np.array(x)\n",
    "        \n",
    "        for i in paired_data:\n",
    "            out.append(self.check_step(i))\n",
    "        match = list(np.array(out) == np.array(y).astype(int))\n",
    "        self.acc = sum(match) / len(match)\n",
    "             \n",
    "    def check_step(self, i):\n",
    "        \n",
    "        # Check the path is in the graph\n",
    "        for j in i:\n",
    "            for k in range(len(j)):\n",
    "                if not j[k] in self.G.nodes:\n",
    "                    return 0\n",
    "                if k >= 1:\n",
    "                    if not (j[k],j[k-1]) in self.G.edges:\n",
    "                        return 0\n",
    "                        \n",
    "        # Check the the pair is possible to have the same st_node   \n",
    "        for node in list(self.G.adj[i[0][0].item()]):\n",
    "            if node in list(self.G.adj[i[1][0].item()]):\n",
    "                return 1\n",
    "\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_algo = Graph_Alg()\n",
    "algo_train_hist = defaultdict(list)\n",
    "num_steps = 20\n",
    "for i in range(num_steps):\n",
    "    data, label = iter(train_loader).next()\n",
    "\n",
    "    # Training\n",
    "    graph_algo.forward(data, label)\n",
    "    \n",
    "    # Testing\n",
    "    v_data, v_label = iter(valid_loader).next()\n",
    "    graph_algo.test(v_data, v_label)\n",
    "    algo_train_hist['Accuracy'].append(graph_algo.acc)\n",
    "    \n",
    "plot_train_hist(algo_train_hist, 'Graph_algo')\n",
    "graph_algo.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese.encoder.h0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
